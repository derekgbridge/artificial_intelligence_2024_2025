{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Introduction</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br />\n",
    "    School of Computer Science and Information Technology<br />\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>What is intelligence?</h1>\n",
    "<ul>\n",
    "    <li>Some people define intelligence in terms of various skills, e.g. reasoning, planning, learning, &hellip;\n",
    "        or playing chess, composing poetry, &hellip;\n",
    "    <li>In particular, these people often concentrate on human skills (chess, language,...), resulting in a very human-centric definition.\n",
    "                <figure style=\"text-align: center;\">\n",
    "                    <img src=\"images/other_intelligences.jpg\" />\n",
    "                    <figcaption>\n",
    "                    Cartoon by <a href=\"https://twitter.com/FalseKnees\">False Knees</a>\n",
    "                    </figcaption>\n",
    "                </figure>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>One example of an approach that is very human-centric is the <i>Turing Test</i> (although this is a test for intelligence, not a definition of intelligence).\n",
    "                <figure style=\"text-align: center;\">\n",
    "                    <img src=\"images/turing.png\" alt=\"The Turing Test: the interrogator must decide which of the others is a machine and which is human.\" />\n",
    "                </figure>\n",
    "                Machines pass the test if the interrogators decide wrongly as often when the goal is to decide which is human and which is a machine as they do when the goal is to decide which is a man and which a woman.\n",
    "            </li>\n",
    "            <li>Question: Do you think ChatGPT passes the Turing Test? (The authors of this paper went so far as to put it to the test &mdash; but with a 5-minute limit: Jones, C. R. and Bergen, B. K. (2024). <a href=\"https://arxiv.org/abs/2405.08007\">People cannot distinguish GPT-4 from a human in a Turing test</a>)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Here are three better definitions:\n",
    "        <ul>\n",
    "            <li>My definition: \"A system's degree of intelligence is defined in terms of its capacity to \n",
    "                act autonomously and rationally when faced with disorder, uncertainty, imprecision and \n",
    "                intractability.\"\n",
    "            </li>\n",
    "            <li>Nils J. Nilsson: \"&hellip;intelligence is that quality that enables an entity to \n",
    "                function appropriately and with foresight in its environment.\"\n",
    "            </li>\n",
    "            <li>Fran&ccedil;ois Chollet: \"The intelligence of a system is a measure of its skill-acquisition \n",
    "                efficiency over a scope of tasks, with respect to priors, experience, and generalization \n",
    "                difficulty.\"\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>No matter how we define it, intelligence is not a Boolean concept (intelligent vs. non-intelligent).</li>\n",
    "    <li>Neither can it be measured on a simple scale (less intelligent, more intelligent) because it manifests in different ways.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>What is AI?</h1>\n",
    "<ul>\n",
    "    <li>AI is the field that studies intelligence by trying to synthesize it.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Is AI even possible?</h1>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid blue; vertical-align: top; text-align: left;\">\n",
    "            <b>No</b>: there's a special and essential ingredient that can't be replicated, e.g. soul, spirit,\n",
    "            consciousness, free will, creativity, humour, &hellip;\n",
    "            <p><br />\n",
    "            Perhaps we can <b>simulate</b> intelligence:\n",
    "            </p>\n",
    "            <ul>\n",
    "                <li>Outwardly, systems may <em>behave as if</em> intelligent.</li>\n",
    "                <li>But, because they lack the special ingredient, the way they achieve this behaviour (the internal process) doesn't qualify as true\n",
    "                    thinking.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td style=\"border: 1px solid blue; vertical-align: top; text-align: left;\">\n",
    "            <b>Yes</b>, we can build <b>true human-like</b> intelligence.\n",
    "        </td>\n",
    "        <td style=\"border: 1px solid blue; vertical-align: top; text-align: left;\">\n",
    "            <b>Yes</b>, we can build true intelligences but they won't necessarily be like us.\n",
    "            <p><br />\n",
    "            AI = <b>alien intelligence</b>.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<ul>\n",
    "    <li>Where do you sit in this table? Or, do you have a different view?</li>\n",
    "    <li>Are humans more than mere animals? Are humans more than mere machines?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Why do we want to build intelligent systems?</h1>\n",
    "<ul>\n",
    "    <li>The goal of most people who work in AI is to build smarter tools.\n",
    "        <ul>\n",
    "            <li>AI = assisted intelligence (helping us with tasks we already do)</li>\n",
    "            <li>AI = augmented intelligence (helping us to do tasks we can't already do)</li>\n",
    "            <li>AI = autonomous intelligence (helping us by doing tasks without our intervention)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Examples\n",
    "        <!--\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td style=\"text-align: left;\">self-driving vehicles</td><td style=\"text-align: right;\"><img src=\"images/car.jpg\" /></td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"text-align: left;\">medical diagnosis tools</td><td style=\"text-align: right;\"><img src=\"images/medicine.jpg\" /></td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"text-align: left;\">bomb disposal robots</td><td style=\"text-align: right;\"><img src=\"images/bomb.jpg\" /></td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        -->\n",
    "        <ul>\n",
    "            <li>Self-driving vehicles;</li>\n",
    "            <li>Healthcare from drug design to screening to resource scheduling to personalised, precision medicine;</li>\n",
    "            <li>Personalised tuition;\n",
    "                <!-- <a href=\"https://openai.com/\">OpenAI</a> already has a partnership with education non-profit <a href=\"https://www.khanacademy.org/\">Khan Academy</a> to explore how ChatGPT could offer a virtual tutor.\n",
    "        They also have a partnership with <a href=\"https://www.duolingo.com/\">Duolingo</a> to use ChaptGPT for teaching modern foreign languages. For a subscription, it allows students to, for example, receive explanations of answers and to engage in role-play. --> \n",
    "            </li>\n",
    "            <li>Better distillation of data, more accurate forecasting, optimisation and control for supply chains, manufacturing activities, and so on;</li>\n",
    "            <li>Multi-purpose domestic robots.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Applied AI versus Artificial General Intelligence (AGI)</h1>\n",
    "<ul>\n",
    "    <li>Applied AI:\n",
    "        <ul>\n",
    "            <li>Currently, we are building systems that are highly specialized, often for a single task in a single domain.\n",
    "            </li>\n",
    "        </ul>\n",
    "        <table style=\"width: 100%;\">\n",
    "             <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/togelius.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                    <a href=\"http://togelius.blogspot.ie/2017/07/some-advice-for-journalists-writing.html\">\n",
    "                    Some advice for journalists writing about AI:\n",
    "                    </a><br />\n",
    "                    \"AI is a collection of methods &hellip; that can do something impressive, such as playing \n",
    "                    a game or drawing pictures of cats. However, you can safely assume that the same system \n",
    "                    cannot both play games and draw pictures of cats. &hellip; [Journalists can] make it seem \n",
    "                    like there are machines with general intelligence out there. There are not.\" (Julian Togelius)\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        <ul>\n",
    "            <li>For Applied AI, we are having some amazing successes, e.g. <a href=\"https://www.nature.com/articles/d41586-020-00018-3\">discovery of a new antibiotic</a> and <a href=\"https://www.nature.com/articles/s41589-023-01349-8\">discovery of another antibiotic</a>; e.g. <a href=\"https://www.newscientist.com/article/2330866-deepminds-protein-folding-ai-cracks-biologys-biggest-problem/\">predicting protein structures</a>; e.g. <a href=\"https://www.nature.com/articles/s41586-023-06004-9\">discovery of faster sorting algorithms</a>.\n",
    "            </li>\n",
    "            <li>But, equally, these Applied AI systems are surprisingly brittle.\n",
    "                <ul>\n",
    "                    <li><a href=\"https://www.theverge.com/tldr/2020/11/3/21547392/ai-camera-operator-football-bald-head-soccer-mistakes\">AI operated camera mistakes bald head for soccer ball</a> (2020)</li>\n",
    "                    <li><a href=\"https://www.theguardian.com/technology/2023/jul/07/san-francisco-autonomous-cars-protest-cone\">Protestors confuse driverless taxis by placing traffic cone on the hood</a> (2023)</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>AGI:\n",
    "        <ul>\n",
    "            <li>No one can really define AGI but it seems to be about showing skill across a wide range of tasks &mdash; at a minimum, the kind of range of tasks that humans are good at.</li>\n",
    "            <li>Opinions differ, but most well-informed people believe we are nowhere near to achieving AGI. The idea that AGI is just around the corner is delusional.\n",
    "            </li>\n",
    "            <li>Impressive bouts of progress are accompanied by hype, even investment, but expectations then haven't panned out.\n",
    "                <ul>\n",
    "                    <!--<li>In 2016 (???), Alpha-Go beat Lee Sedol (???), Go grand-master (???), an a Go tournament. Alpha-Go used deep reinforcement learning (see AI2 lectures). Expectation that we would....sel-learning... what??</li> -->\n",
    "                    <li>Example: Since 2016, we've been watching impressive videos of robots, especialy from Boston Dynamics. The hype was that multi-purpose domestic robots (ones that can clear the table and fill the dishwasher, for example) would be in our homes within 5-10 years. Where are they?</li>\n",
    "                    <li>Example: Since 2016, we've been impressed by self-driving cars such as those produced by Google's off-shoot, Waymo. The hype was that self-driving cars were just 5-10 years away. What we have now are self-driving cars that are hugely impressive but which operate in geo-fenced areas (two or three cities so far) and with considerable human oversight and intervention. Humans, by contrast, drive pretty well almost anywhere.</li>\n",
    "                    <li>Example: Systems, such as ChatGPT, built atop of Large Language Models (see AI2 lectures) are impressive. Before 2023, no one anticipated how impressive such dumb technology would be. But now, there's a lot of hype. People are assuming that these systems already possess capabilities that they do not. They do not possess human-level understanding: 5-minutes with ChatGPT should make that clear. There will be a lot of fancy demos and a tsunami of marketing hyperbole over the coming year or so. Be skeptical!</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "        Current AI systems do not know how the world works, and (arguably) we don't really know how to equip them with this knowledge.\n",
    "        <table style=\"width: 100%;\">\n",
    "            <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/lecun.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                            \"Before we can get to \"God-like AI\" we'll need to get through \"Dog-like AI\".\" (Yann LeCun)\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Risks</h1>\n",
    "<ul>\n",
    "    <li>Debate about the risks of AI is as old as AI itself.</li>\n",
    "    <li>But since the launch of ChaptGPT, there is a frenzy.</li>\n",
    "    <li>The following notes are intended to be thought-provoking, rather than comprehensive.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Existential risks</h2>\n",
    "<ul>\n",
    "    <li>There is a lot of discussion of existential risks.\n",
    "        <ul>\n",
    "            <li>There is a risk, it is claimed, of extinction or enslavement of the human race by a rogue AI.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Here are some of the warnings:\n",
    "        <table style=\"width: 100%;\">\n",
    "            <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/hawking.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                            \"The development of full artificial intelligence could spell the end of the human\n",
    "                            race&hellip;It would take off on its own, and re-design itself at an ever \n",
    "                            increasing rate.\" (Stephen Hawking)\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/musk.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                            \"&hellip;the most serious threat to the survival of the human race&hellip;\" (Elon Musk)\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/altman.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                            “My worst fear is that we—the field, the technology, the industry—cause significant harm to the world.” (Sam Altman)\n",
    "                </td>\n",
    "            </tr>\n",
    "            <!--\n",
    "            <li>In March 2023, the so-called Future of Life Institute called for a pause of at least 6 months on research into AI systems of at least the complexity of GPT-4. Their <a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\">letter</a> was signed by many tech leaders and some AI scientists.</li>\n",
    "            <li>In May 2023, the so-called Center for AI Safety released a statement: \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.'' (Question: why no mention of climate change?) The statement was signed by many tech leaders and AI scientists, including Sam Altman, the CEO of OpenAI, the organisation responsible for ChatGPT.</li>\n",
    "            -->\n",
    "            <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/hinton.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                            In 2023, Geoff Hinton, great-great-grandson of George Boole, sometimes referred to as one of the \"godfathers of AI\" for his pioneering work in deep learning, resigned from Google so that he could \"freely speak out about the risks of A.I.\". He says he partly regrets his life's work, and he has spoken about AI wiping out humanity.\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </li>\n",
    "    <li>\n",
    "       Some people are genuinely bewildered by these warnings.\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/ng.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                            \"I don’t work on not turning AI evil today for the same reason I don't worry \n",
    "                            about the problem of overpopulation on the planet Mars.\" (2015)<br /><br />\n",
    "                            \"I'd like to have a real conversation about whether AI is a risk for human extinction. Honestly, I don't get how AI poses this risk.\" (2023) (Andrew Ng)\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </li>\n",
    "    <!--<li>For conciseness, in what follows I shall refer to the people who are warning about existential risks as The Apocalypticists.</li>-->\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Super-intelligence</h2>\n",
    "<ul>\n",
    "    <li>In some cases, the fears depend on the emergence of a super-intelligence and one that is not aligned with human values.\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td style=\"border-right-width: 0\"><img style=\"width: 100px\" src=\"images/bostrom.jpg\" /></td>\n",
    "                <td style=\"border-left-width: 0; text-align: left;\">\n",
    "                    Imagine a super-intelligence with the goal of making as many paper-clips as possible.\n",
    "                    `The AI will realize quickly that it would be much better if there were no humans because humans might decide to switch it off. Because if humans do so, there would be fewer paper clips. Also, human bodies contain a lot of atoms that could be made into paper clips. The future that the AI would be trying to gear towards would be one in which there were a lot of paper clips but no humans.'' (Nick Bostrom)\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </li>\n",
    "    <!--\n",
    "    <li>Many AI scientists and AI ethics researchers did not sign the letters and statements mentioned above.\n",
    "    </li>\n",
    "    -->\n",
    "    <!--\n",
    "    <li>Let's consider what causes extinctions and societal collapse.\n",
    "        <ul>\n",
    "            <li>Extinctions in nature occur when changes to environmental conditions destroy a species' ecological niche. Think climate change and catastrophes such as large meteorites, for example.</li>\n",
    "            <li>One species may contribute to the extinction of another when there is competition for resources or when one species is over-hunted by the other.</li>\n",
    "            <li>Advanced human civilisations always collapse. Think of the Ancient Greeks, Ancient Egyptians, Ancient Romans, Aztecs, Mayans, Incas, Easter Islanders, and so on. The causes include environmental degradation, gross inequality, societal over-complexity, war, natural disaster, famine and plague. Public services get stretched. Under pressure, people use violence to achieve their personal goals.</li>\n",
    "        </ul>\n",
    "        Do these explain what The Apocolypticists think will happen?\n",
    "    </li>\n",
    "    -->\n",
    "    <li>However, even defining super-intelligence is fraught. (Defining intelligence was hard enough: see earlier!)\n",
    "        <ul>\n",
    "            <li>The concept may not even be meaningful.</li>\n",
    "            <li>There may even be constraints on intelligence.</li>\n",
    "            <li>And, in the thought experiment, the super-intelligence is smart enough to develop technologies to mine metals from human corpses while at the same time it lacks common-sense (who would use all those paper-clips?) and it lacks moral values. Is this even coherent?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>In fact, a greater fear should probably be a not-so-bright AI making poor decisions that cause havoc, e.g. decisions that disrupt food supply or health service delivery.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>More pressing AI risks</h2>\n",
    "<ul>\n",
    "    <li>More worrying, some people believe that focusing on the possibility of human extinction or enslavement may itself be harmful.</li>\n",
    "    <li>It distracts regulators, politicians, the public and AI researchers from more pressing AI risks such as:\n",
    "        <ul>\n",
    "            <li>mass surveillance by governments and by big tech;</li>\n",
    "            <li>disinformation and manipulation of opinion;</li>\n",
    "            <li>military uses and misuses;</li>\n",
    "            <li>cybersecurity uses and misuses.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>It also distracts from the present and future socio-economic consequences of AI, which include:\n",
    "        <ul>\n",
    "            <li>possible mass unemployment;</li>\n",
    "            <li>the high energy and water costs of data centres;</li>\n",
    "            <li>the en-shit-tification of online spaces (ads, spam, clickbait, phishing, web site customer support chatbots, fake reviews, anti-scientific conspiracy theorists, Jordan Peterson, abuse, pile-ons, catfish, bullying, hate speech, Andrew Tait, dick pics, public shaming, Donald Trump, AI-generated news &hellip;) &mdash; some of which is amplified by AI;</li>\n",
    "            <li>concentration of wealth and power in the hands of big tech and authoritarian governments.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>It also distracts from the flaws with current AI. These flaws include:\n",
    "        <ul>\n",
    "            <li>brittleness;</li>\n",
    "            <li>bias;</li>\n",
    "            <li>invasion of privacy;</li>\n",
    "            <li>concoction of falsehoods ('hallucinations');</li>\n",
    "            <li>lack of explainability/interpretability.</li>\n",
    "        </ul>\n",
    "        <em>Some people conclude that the problem with AI is not that it is too good. \n",
    "            The real problem with AI is that it is not good enough.</em>\n",
    "    </li>\n",
    "    <!--<li>To be fair, although The Apocalpyticists do warn of existential risks, some of their proposals also overlap with items listed above.</li>-->\n",
    "</ul>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><figure><img src=\"images/gebru.png\" alt=\"Timnit Gebru\" /><figcaption>Timnit Gebru</figcaption></figure></td>\n",
    "        <td><figure><img src=\"images/mitchell.jpg\" alt=\"Margaret Mitchell\" /><figcaption>Margaret Mitchell</figcaption></figure></td>\n",
    "        <td><figure><img src=\"images/birhane.png\" alt=\"Abeba Birhane\" /><figcaption>Abeba Birhane</figcaption></figure></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Motives</h2>\n",
    "<ul>\n",
    "    <li>What are the motives of the people who are warning of existential risks?</li>\n",
    "    <li>Are tech leaders trying to distract us from the near-term risks, or are they trying to cement their monopoly positions?</li>\n",
    "    <li>More likely than the conspiracy theories is any number of simpler explanations: some of these people are attention-seekers; some seem to relish being part of a larger-than-life narrative; some are thinking about their reputations &mdash; they don't want to be seen to be on the wrong side of history; some just don't understand the tech; and most are sincere but naive about the consequences of misleading the public and of misdirecting corporate and government priorities.</li>\n",
    "    <li>Nevertheless, there is good reason to question the motives of even the most sincere of them. They have not notably distinguished themselves in the past by supporting people who have been warning about nearer-term risks. E.g. where were these people when <a href=\"https://www.theguardian.com/lifeandstyle/2023/may/22/there-was-all-sorts-of-toxic-behaviour-timnit-gebru-on-her-sacking-by-google-ais-dangers-and-big-techs-biases\">Google terminated the employment of Timnit Gebru for publishing a paper that warned of the near-term dangers of large language models</a>?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Regulation</h2>\n",
    "<ul>\n",
    "    <li>Oren Etzioni has offered for debate his <a href=\"https://dl.acm.org/doi/pdf/10.1145/3197382\">five guidelines for regulating AI applications</a>:\n",
    "                <ul>\n",
    "                    <li>Don't weaponise AI.</li>\n",
    "                    <li>An AI system is subject to the full gamut of laws that apply to its human operator. (In other words, humans &mdash;the owner or manufacturer&mdash; are responsible for ensuring that their AI systems do not harm anyone.)</li>\n",
    "                    <li>An AI system shall clearly disclose that it is not human. Similarly, AI-generated outputs must be flagged as such.</li>\n",
    "                    <li>An AI system shall not retain or disclose confidential information without explicit prior approval from the source.</li>\n",
    "                    <li>An AI system must not increase any bias that already exists in our systems.</li>\n",
    "                </ul>\n",
    "    </li>\n",
    "    <li><!--The Apocalpyticists are also giving the impression that nothing is being done --> And there is progress on the regulatory front. <!-- That's not true. -->\n",
    "        <ul>\n",
    "            <li>The EU has passed its <a href=\"https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence\">AI Act</a>. The Act classifies systems according to risk, with different rules accordingly.\n",
    "                <ul>\n",
    "                    <li>Unacceptable risk: these systems are banned. E.g. social scoring of the kind done in China; predictive policing; real-time facial recognition.</li>\n",
    "                    <li>High risk: these systems must be assessed before being put on the market and must be checked periodically. E.g. systems for use in education, law enforcement, border control, and medical devices.</li>\n",
    "                    <li>Limited risk: these systems are expected to adhere to some basic transparency regulations. E.g. AI-generated content must be flagged in some way; summaries of training data must be published.</li>\n",
    "                    <li>Minimal or no risk: the Act places no extra obligations on these systems. E.g. spam filters.</li>\n",
    "                </ul>\n",
    "                <!-- The goal is to legislate by the end of 2023. -->\n",
    "                Critics say that the Act will stifle innovation.\n",
    "            </li>\n",
    "            <!--\n",
    "            <li>The UK has published a policy paper, entitled <a href=\"https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper\">A pro-innovation approach to AI regulation</a>. They claim that their approach will be to regulate outcomes, not the technology; for example, a chatbot for customer support for an online clothing retailer should not be regulated in the same way as a chatbot used as part of a medical diagnostic process. They list five principles: safety, security &amp; robustness; appropriate transparency &amp; explainability; fairness; accountability &amp; governance; and contestability &amp; redress.</li>\n",
    "            -->\n",
    "            <li>Lots of other bodies are publishing their own deliberations on AI regulation: <a href=\"https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper\">The UK's policy paper on AI regulation</a>; <a href=\"https://monoskop.org/images/d/d2/Montreal_Declaration_for_a_Responsible_Development_of_Artificial_Intelligence_2018.pdf\">The Montreal Declaration on Responsible AI</a>; <a href=\"https://www3.weforum.org/docs/WEF_Presidio_Recommendations_on_Responsible_Generative_AI_2023.pdf\">The World Economic Forum's Presidio Recommendations on Responsible Generative AI</a>; <a href=\"https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai\">Ethics Guidelines for Trustworthy AI</a>; <a href=\"https://futureoflife.org/open-letter/ai-principles/\">The Asilomar AI Principles</a>; Y. Bengio et al.: <a href=\"https://arxiv.org/abs/2310.17688\">Managing extreme AI risks amid rapid progress\"</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Of course, regrettably there is no sign of regulation in the USA or in China or at a global level.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Education</h2>\n",
    "<ul>\n",
    "    <li>As important as regulation is education.</li>\n",
    "    <li>Regulators, policiticians, tech leaders, journalists and the public need to understand AI better.</li>\n",
    "    <li>How else can they judge the risks, develop appropriate regulation, and steer AI to a positive future?</li>\n",
    "    <!--\n",
    "    <li>If you want to play your part in this, then encourage your friends and family to take the following free on-line course: <a href=\"https://www.elementsofai.com/ie\">Elements of AI</a>, developed by the University of Helsinki and operated in Ireland by Barry O Sullivan and me.</li>\n",
    "    -->\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2>\n",
    "<ul>\n",
    "    <li>Of course, it is responsible to think about the existential risks of AI.</li>\n",
    "    <li>But it does not warrant being a global priority alongside prevention of nuclear war, pandemics and catastrophic climate change.</li>\n",
    "    <li>We should devote relatively more of our limited bandwidth into regulation efforts of the near-term risks. Doing so may even avoid some of the more remote possibilities.</li>\n",
    "    <li>Regulation should be at the right level of abstraction: it should focus on (i) outcomes, not specific technologies, and (ii) processes for responsible development and deployment of technologies.</li>\n",
    "    <li>Education is crucial, too.</li>\n",
    "    <li>Finally, we should avoid \"moral outsourcing\": blaming machines for human decisions. It's not AI that brings mass unemployment, bias in decision-making, en-shit-tification, etc. It's the decisions taken by people like us &mdash; the people who design and deploy these technologies. Regulation should not be about protecting us from technologies. It should be about how societies collectively shape their futures.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
